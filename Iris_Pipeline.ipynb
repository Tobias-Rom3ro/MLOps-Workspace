{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIMwTV2d7Kee9W9MYoLSlw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tobias-Rom3ro/Pipeline-DirtyIris/blob/main/Iris_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Pipeline de Entrenamiento de ML con Dataset Iris."
      ],
      "metadata": {
        "id": "nO62Vj-kT1JA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importaci贸n de librer铆as."
      ],
      "metadata": {
        "id": "uUJdCtYxTwhA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Sebw1hV5Q9Xz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Funciones auxiliares."
      ],
      "metadata": {
        "id": "dTRjL6LjUTj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    \"\"\"Solo carga los datos del CSV\"\"\"\n",
        "    return pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "JpklhBo_UW4m"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_target_variable(df):\n",
        "    \"\"\"Prepara la variable target aplicando la misma limpieza\"\"\"\n",
        "    Species_mapping = {\n",
        "        'setosa': 'setosa',\n",
        "        'iris-setosa': 'setosa',\n",
        "        'versicolor': 'versicolor',\n",
        "        'iris-versicolor': 'versicolor',\n",
        "        'virginica': 'virginica',\n",
        "        'iris-virginica': 'virginica'\n",
        "    }\n",
        "\n",
        "    # Limpiar eSpecies para y\n",
        "    y_clean = df['Species'].str.lower().str.strip().map(Species_mapping)\n",
        "\n",
        "    # Codificar\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(y_clean)\n",
        "\n",
        "    return y_encoded, label_encoder"
      ],
      "metadata": {
        "id": "3FNok4ITUZ9Y"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Transformers personalizados."
      ],
      "metadata": {
        "id": "-x1ultJTT_Cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataExplorer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Transformer que explora y muestra informaci贸n de los datos\"\"\"\n",
        "\n",
        "    def __init__(self, verbose=True):\n",
        "        self.verbose = verbose\n",
        "        self.original_shape = None\n",
        "        self.Species_counts = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if self.verbose:\n",
        "            print(\"=\"*50)\n",
        "            print(\"PASO 1: EXPLORACIN DE DATOS\")\n",
        "            print(\"=\"*50)\n",
        "            print(f\"Forma del dataset: {X.shape}\")\n",
        "            print(\"\\nPrimeras 5 filas:\")\n",
        "            print(X.head())\n",
        "\n",
        "            if 'Species' in X.columns:\n",
        "                print(\"\\nValores 煤nicos en Species (antes de limpiar):\")\n",
        "                print(X['Species'].value_counts())\n",
        "\n",
        "            print(\"\\nValores nulos:\")\n",
        "            print(X.isnull().sum())\n",
        "\n",
        "        self.original_shape = X.shape\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X"
      ],
      "metadata": {
        "id": "z8Seh42gUHUW"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpeciesCleaner(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Transformer que limpia autom谩ticamente los nombres de eSpecies\"\"\"\n",
        "\n",
        "    def __init__(self, verbose=True):\n",
        "        self.verbose = verbose\n",
        "        self.Species_mapping = {\n",
        "            'setosa': 'setosa',\n",
        "            'iris-setosa': 'setosa',\n",
        "            'versicolor': 'versicolor',\n",
        "            'iris-versicolor': 'versicolor',\n",
        "            'virginica': 'virginica',\n",
        "            'iris-virginica': 'virginica'\n",
        "        }\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if self.verbose:\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"PASO 2: LIMPIEZA DE ESpecies\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "        df = X.copy()\n",
        "\n",
        "        if 'Species' in df.columns:\n",
        "            # Mostrar antes de limpiar\n",
        "            if self.verbose:\n",
        "                print(\"ESpecies antes de limpiar:\")\n",
        "                print(df['Species'].value_counts())\n",
        "\n",
        "            # Limpiar eSpecies\n",
        "            df['Species'] = df['Species'].str.lower().str.strip()\n",
        "            df['Species'] = df['Species'].map(self.Species_mapping)\n",
        "\n",
        "            # Mostrar despu茅s de limpiar\n",
        "            if self.verbose:\n",
        "                print(\"\\nESpecies despu茅s de limpiar:\")\n",
        "                print(df['Species'].value_counts())\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "TgSox1lgUIMU"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Transformer que selecciona solo las features num茅ricas\"\"\"\n",
        "\n",
        "    def __init__(self, verbose=True):\n",
        "        self.verbose = verbose\n",
        "        self.feature_columns = ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if self.verbose:\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"PASO 3: SELECCIN DE FEATURES\")\n",
        "            print(\"=\"*50)\n",
        "            print(f\"Columnas originales: {list(X.columns)}\")\n",
        "            print(f\"Features seleccionadas: {self.feature_columns}\")\n",
        "\n",
        "        df = X.copy()\n",
        "        selected_features = df[self.feature_columns]\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"Forma despu茅s de selecci贸n: {selected_features.shape}\")\n",
        "\n",
        "        return selected_features"
      ],
      "metadata": {
        "id": "HBxnfDmiUL9Q"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Creaci贸n del pipeline completo."
      ],
      "metadata": {
        "id": "Lh-jxb1cUeZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_complete_pipeline():\n",
        "    # Pipeline de preprocesamiento para features num茅ricas\n",
        "    feature_cols = ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\n",
        "\n",
        "    numeric_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    # ColumnTransformer para manejar las features\n",
        "    preprocessor = ColumnTransformer([\n",
        "        ('numeric', numeric_pipeline, feature_columns)\n",
        "    ], remainder='drop')\n",
        "\n",
        "    complete_pipeline = Pipeline([\n",
        "        ('explorer', DataExplorer(verbose=True)),\n",
        "        ('cleaner', SpeciesCleaner(verbose=True)),\n",
        "        ('selector', FeatureSelector(verbose=True)),\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "    ])\n",
        "\n",
        "    return complete_pipeline"
      ],
      "metadata": {
        "id": "WSamaYUDUeI9"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Entrenamiento, evaluaci贸n y guardado del pipeline."
      ],
      "metadata": {
        "id": "5LA6W4KbUtT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_iris_pipeline(file_path, test_size=0.2, random_state=42):\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"ENTRENAMIENTO CON PIPELINE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. Cargar datos\n",
        "    print(\"Cargando datos del archivo:\", file_path)\n",
        "    df = load_data(file_path)\n",
        "    print(\"Columnas despu茅s de cargar:\", df.columns.tolist()) # Add this line to check columns\n",
        "\n",
        "\n",
        "    # 2. Aplicar DataExplorer y SpeciesCleaner antes de preparar target\n",
        "    print(\"\\nAplicando DataExplorer y SpeciesCleaner...\")\n",
        "    data_explorer = DataExplorer(verbose=True)\n",
        "    df_explored = data_explorer.transform(df) # Just for exploration output\n",
        "    Species_cleaner = SpeciesCleaner(verbose=True)\n",
        "    df_cleaned = Species_cleaner.transform(df_explored)\n",
        "    print(\"Columnas despu茅s de limpiar eSpecies:\", df_cleaned.columns.tolist()) # Add this line to check columns\n",
        "\n",
        "\n",
        "    # 3. Preparar target\n",
        "    print(\"\\nPreparando variable target...\")\n",
        "    y, label_encoder = prepare_target_variable(df_cleaned)\n",
        "\n",
        "    # 4. Define features (X) after cleaning Species but before selecting numeric ones\n",
        "    X = df_cleaned.drop('Species', axis=1, errors='ignore') # Drop Species from features for pipeline input\n",
        "\n",
        "\n",
        "    # 5. Divisi贸n de datos\n",
        "    print(f\"\\nDividiendo datos ({int((1-test_size)*100)}% entrenamiento, {int(test_size*100)}% prueba)...\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "    print(f\"Entrenamiento: {X_train.shape[0]} muestras\")\n",
        "    print(f\"Prueba: {X_test.shape[0]} muestras\")\n",
        "\n",
        "    # 6. Crear pipeline (Starts with FeatureSelector for X_train)\n",
        "    print(\"\\nCreando pipeline de entrenamiento...\")\n",
        "    feature_columns = ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\n",
        "\n",
        "    numeric_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer([\n",
        "        ('numeric', numeric_pipeline, feature_columns)\n",
        "    ], remainder='drop')\n",
        "\n",
        "\n",
        "    complete_pipeline = Pipeline([\n",
        "        ('selector', FeatureSelector(verbose=True)), # Select features from X\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "    ])\n",
        "\n",
        "\n",
        "    # 7. ENTRENAR\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ENTRENANDO PIPELINE\")\n",
        "    print(\"=\"*60)\n",
        "    # Fit the pipeline on the training features and target\n",
        "    complete_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # 8. EVALUAR\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EVALUANDO PIPELINE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    y_pred = complete_pipeline.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nReporte de clasificaci贸n:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "    print(\"\\nMatriz de confusi贸n:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # 9. Guardar pipeline\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"GUARDANDO PIPELINE\")\n",
        "    print(\"=\"*60)\n",
        "    joblib.dump(complete_pipeline, 'complete_iris_pipeline.pkl')\n",
        "    joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "    print(\"Pipeline guardado en: complete_iris_pipeline.pkl\")\n",
        "    print(\"Label encoder guardado en: label_encoder.pkl\")\n",
        "\n",
        "    return complete_pipeline, label_encoder"
      ],
      "metadata": {
        "id": "ZpyOmKR1U4mw"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Ejecuci贸n principal."
      ],
      "metadata": {
        "id": "HCj9U_F5Wj_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    file_path = 'iris_dirty.csv'\n",
        "    trained_pipeline, label_encoder = train_iris_pipeline(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8jCLuydWgVx",
        "outputId": "14be3f64-016e-41c0-f18e-ee3b6c914cfb"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ENTRENAMIENTO CON PIPELINE\n",
            "============================================================\n",
            "Cargando datos del archivo: iris_dirty.csv\n",
            "Columnas despu茅s de cargar: ['Unnamed: 0', 'Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width', 'Species']\n",
            "\n",
            "Aplicando DataExplorer y SpeciesCleaner...\n",
            "\n",
            "==================================================\n",
            "PASO 2: LIMPIEZA DE ESpecies\n",
            "==================================================\n",
            "ESpecies antes de limpiar:\n",
            "Species\n",
            "virginica     49\n",
            "setosa        48\n",
            "versicolor    48\n",
            "Setosa         1\n",
            "SETOSA         1\n",
            "Versicolor     1\n",
            "VERSICOLOR     1\n",
            "VIRGINICA      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ESpecies despu茅s de limpiar:\n",
            "Species\n",
            "setosa        50\n",
            "versicolor    50\n",
            "virginica     50\n",
            "Name: count, dtype: int64\n",
            "Columnas despu茅s de limpiar eSpecies: ['Unnamed: 0', 'Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width', 'Species']\n",
            "\n",
            "Preparando variable target...\n",
            "\n",
            "Dividiendo datos (80% entrenamiento, 20% prueba)...\n",
            "Entrenamiento: 120 muestras\n",
            "Prueba: 30 muestras\n",
            "\n",
            "Creando pipeline de entrenamiento...\n",
            "\n",
            "============================================================\n",
            "ENTRENANDO PIPELINE\n",
            "============================================================\n",
            "\n",
            "==================================================\n",
            "PASO 3: SELECCIN DE FEATURES\n",
            "==================================================\n",
            "Columnas originales: ['Unnamed: 0', 'Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\n",
            "Features seleccionadas: ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\n",
            "Forma despu茅s de selecci贸n: (120, 4)\n",
            "\n",
            "============================================================\n",
            "EVALUANDO PIPELINE\n",
            "============================================================\n",
            "\n",
            "==================================================\n",
            "PASO 3: SELECCIN DE FEATURES\n",
            "==================================================\n",
            "Columnas originales: ['Unnamed: 0', 'Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\n",
            "Features seleccionadas: ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\n",
            "Forma despu茅s de selecci贸n: (30, 4)\n",
            "Accuracy: 0.9333\n",
            "\n",
            "Reporte de clasificaci贸n:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       0.90      0.90      0.90        10\n",
            "   virginica       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.93      0.93      0.93        30\n",
            "weighted avg       0.93      0.93      0.93        30\n",
            "\n",
            "\n",
            "Matriz de confusi贸n:\n",
            "[[10  0  0]\n",
            " [ 0  9  1]\n",
            " [ 0  1  9]]\n",
            "\n",
            "============================================================\n",
            "GUARDANDO PIPELINE\n",
            "============================================================\n",
            "Pipeline guardado en: complete_iris_pipeline.pkl\n",
            "Label encoder guardado en: label_encoder.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Usar el pipeline entrenado."
      ],
      "metadata": {
        "id": "shhRzfwrWshD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pipeline():\n",
        "    \"\"\"Carga el pipeline entrenado\"\"\"\n",
        "    pipeline = joblib.load('complete_iris_pipeline.pkl')\n",
        "    label_encoder = joblib.load('label_encoder.pkl')\n",
        "    return pipeline, label_encoder"
      ],
      "metadata": {
        "id": "PXQjZvgKWr2L"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_new_samples(pipeline, label_encoder, new_data):\n",
        "    \"\"\"Usa el pipeline para predecir nuevas muestras\"\"\"\n",
        "    predictions = pipeline.predict(new_data)\n",
        "    probabilities = pipeline.predict_proba(new_data)\n",
        "    Species_names = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "    return Species_names, probabilities"
      ],
      "metadata": {
        "id": "27SRhDO2WxeI"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Prueba con datos ficticios."
      ],
      "metadata": {
        "id": "rbE5kCRmW1fT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Cargar pipeline entrenado\n",
        "    pipeline, label_encoder = load_pipeline()\n",
        "\n",
        "    # Crear datos ficticios\n",
        "    test_data = pd.DataFrame({\n",
        "        'Sepal.Length': [5.1, 6.2, 7.3, 4.8, 5.8],\n",
        "        'Sepal.Width': [3.5, 2.2, 2.9, 3.0, 2.7],\n",
        "        'Petal.Length': [1.4, 4.5, 6.3, 1.4, 5.1],\n",
        "        'Petal.Width': [0.2, 1.5, 1.8, 0.1, 1.9],\n",
        "        'Species': ['SETOSA', 'iris-versicolor', 'VIRGINICA', 'setosa', 'unknown']  # Datos sucios a prop贸sito\n",
        "    })\n",
        "\n",
        "    print(\"Datos de prueba (sucios):\")\n",
        "    print(test_data)\n",
        "\n",
        "    Species_predictions, probabilities = predict_new_samples(pipeline, label_encoder, test_data)\n",
        "\n",
        "    print(\"\\nRESULTADOS:\")\n",
        "    print(\"-\"*50)\n",
        "    for i, (pred, prob) in enumerate(zip(Species_predictions, probabilities)):\n",
        "        max_prob = max(prob)\n",
        "        print(f\"Muestra {i+1}: {pred} (confianza: {max_prob:.4f})\")\n",
        "\n",
        "        for Species, probability in zip(label_encoder.classes_, prob):\n",
        "            print(f\"  {Species}: {probability:.4f}\")\n",
        "        print()\n",
        "\n",
        "    print(\"Pipeline funcionando perfectamente\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Pipeline no encontrado.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPA7QzTVW5Bc",
        "outputId": "7086665e-abbb-4a2e-ac1d-e5482610f6ee"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos de prueba (sucios):\n",
            "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width          Species\n",
            "0           5.1          3.5           1.4          0.2           SETOSA\n",
            "1           6.2          2.2           4.5          1.5  iris-versicolor\n",
            "2           7.3          2.9           6.3          1.8        VIRGINICA\n",
            "3           4.8          3.0           1.4          0.1           setosa\n",
            "4           5.8          2.7           5.1          1.9          unknown\n",
            "\n",
            "==================================================\n",
            "PASO 3: SELECCIN DE FEATURES\n",
            "==================================================\n",
            "Columnas originales: ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width', 'Species']\n",
            "Features seleccionadas: ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\n",
            "Forma despu茅s de selecci贸n: (5, 4)\n",
            "\n",
            "==================================================\n",
            "PASO 3: SELECCIN DE FEATURES\n",
            "==================================================\n",
            "Columnas originales: ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width', 'Species']\n",
            "Features seleccionadas: ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\n",
            "Forma despu茅s de selecci贸n: (5, 4)\n",
            "\n",
            "RESULTADOS:\n",
            "--------------------------------------------------\n",
            "Muestra 1: setosa (confianza: 1.0000)\n",
            "  setosa: 1.0000\n",
            "  versicolor: 0.0000\n",
            "  virginica: 0.0000\n",
            "\n",
            "Muestra 2: versicolor (confianza: 0.9700)\n",
            "  setosa: 0.0000\n",
            "  versicolor: 0.9700\n",
            "  virginica: 0.0300\n",
            "\n",
            "Muestra 3: virginica (confianza: 1.0000)\n",
            "  setosa: 0.0000\n",
            "  versicolor: 0.0000\n",
            "  virginica: 1.0000\n",
            "\n",
            "Muestra 4: setosa (confianza: 1.0000)\n",
            "  setosa: 1.0000\n",
            "  versicolor: 0.0000\n",
            "  virginica: 0.0000\n",
            "\n",
            "Muestra 5: virginica (confianza: 1.0000)\n",
            "  setosa: 0.0000\n",
            "  versicolor: 0.0000\n",
            "  virginica: 1.0000\n",
            "\n",
            "Pipeline funcionando perfectamente\n"
          ]
        }
      ]
    }
  ]
}